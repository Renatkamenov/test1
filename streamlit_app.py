
import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
from unet import UNet
import gdown
import os

# === –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏–∑ Google Drive ===
def download_weights_if_needed():
    if not os.path.exists("model.pth"):
        gdown.download(id="1YOiR43UNS6uddwOm2dfT5XYaZKAZp1KA", output="model.pth", quiet=False)
    if not os.path.exists("model_classifier.pth"):
        gdown.download(id="12IYj0cjpMsWPeTOZMlgqZ2pucziMrutC", output="model_classifier.pth", quiet=False)

download_weights_if_needed()

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMG_SIZE = 256
CLS_SIZE = 224

CLASSES = ['MT_Blowhole', 'MT_Break', 'MT_Crack', 'MT_Fray', 'MT_Free', 'MT_Uneven']
DEFECT_LABELS = {
    "MT_Blowhole": "–ü–æ—Ä–∏—Å—Ç–æ—Å—Ç—å",
    "MT_Break": "–†–∞–∑—Ä—ã–≤",
    "MT_Crack": "–¢—Ä–µ—â–∏–Ω–∞",
    "MT_Fray": "–ò–∑–Ω–æ—à–µ–Ω–Ω–æ—Å—Ç—å –∫—Ä–∞—è",
    "MT_Free": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–∞",
    "MT_Uneven": "–ù–µ—Ä–æ–≤–Ω–æ—Å—Ç—å"
}

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ===
@st.cache_resource
def load_unet():
    model = UNet()
    model.load_state_dict(torch.load("model.pth", map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    return model

@st.cache_resource
def load_resnet():
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, len(CLASSES))
    model.load_state_dict(torch.load("model_classifier.pth", map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    return model

# === –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ===
tf_unet = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

tf_resnet = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(CLS_SIZE),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
st.title("üß† –ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã ‚Äî UNet + ResNet")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ú–æ–¥–µ–ª—å –≤—ã–¥–µ–ª–∏—Ç –¥–µ—Ñ–µ–∫—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ–≥–æ —Ç–∏–ø.")

uploaded_file = st.file_uploader("üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ .jpg/.png", type=["jpg", "jpeg", "png"])

if uploaded_file:
    orig_img = Image.open(uploaded_file).convert("RGB")

    # === UNet —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è ===
    unet_input = tf_unet(orig_img).unsqueeze(0).to(DEVICE)
    unet = load_unet()
    with torch.no_grad():
        output = unet(unet_input)
        mask = torch.sigmoid(output).squeeze().cpu().numpy()
        mask = (mask > 0.5).astype(np.uint8)

    # –ú–∞—Å–∫–∞ + –Ω–∞–ª–æ–∂–µ–Ω–∏–µ
    img_resized = orig_img.resize((IMG_SIZE, IMG_SIZE))
    mask_img = Image.fromarray((mask * 255).astype(np.uint8))
    overlay = Image.new("RGBA", img_resized.size, (255, 0, 0, 0))
    overlay_np = np.array(overlay)
    mask_np = np.array(mask_img)
    overlay_np[mask_np > 0] = [255, 0, 0, 100]
    overlay = Image.fromarray(overlay_np, mode="RGBA")
    result_img = Image.alpha_composite(img_resized.convert("RGBA"), overlay)

    # === ResNet –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ===
    resnet_input = tf_resnet(orig_img).unsqueeze(0).to(DEVICE)
    resnet = load_resnet()
    with torch.no_grad():
        pred = resnet(resnet_input)
        pred_class = CLASSES[pred.argmax(1).item()]
        pred_desc = DEFECT_LABELS.get(pred_class, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–µ—Ñ–µ–∫—Ç")

    # === –í—ã–≤–æ–¥
    st.subheader("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:")
    st.image(result_img, caption="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã", use_container_width=True)
    st.markdown(f"### üìå –¢–∏–ø –¥–µ—Ñ–µ–∫—Ç–∞: **{pred_desc} ({pred_class})**")
